{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f05df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 09:03:50.685617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-11 09:03:50.968931: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf260ab6-6b5b-415d-83ff-70d29edeaa88",
   "metadata": {},
   "source": [
    "This is the data set used by Gorman and Sejnowski in their study of the classification of sonar signals using a neural network: Gorman, R. P., and Sejnowski, T. J. (1988);  “Analysis of Hidden Units in a Layered Network Trained to Classify Sonar Targets” in Neural Networks, Vol. 1, pp. 75-89.\n",
    "The task is to train a network to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock.\n",
    "The original files can be found at the adress: http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d150d7c-a0a0-4e77-bdc9-ed0528b8c8fa",
   "metadata": {},
   "source": [
    "The file “sonar.mines” contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions. The file “sonar.rocks” contains 97 patterns obtained from rocks under similar conditions. The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.\n",
    "\n",
    "Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.\n",
    "\n",
    "The label associated with each record contains the letter “R” if the object is a rock and “M” if it is a mine (metal cylinder). The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6554a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# the file sonar.all-data of the UCI repository is renamed \"sonar.csv\"\n",
    "dataframe = pd.read_csv(\"sonar.csv\", header=None)\n",
    "data = dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d387247",
   "metadata": {},
   "source": [
    "## Separation between training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212688db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10858ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfc7bf-0c8f-48aa-b797-cd971c11326a",
   "metadata": {},
   "source": [
    "First, we write a function that gives the repartition between the two labels in a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2aa6303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "R  total :  46.63461538461539\n",
      "M  total :  53.36538461538461\n"
     ]
    }
   ],
   "source": [
    "def repartition(tab,label):\n",
    "    nR=0; nM=0\n",
    "    nb = len(tab[:,60])\n",
    "    print(nb)\n",
    "    for i in range(nb):\n",
    "        if(tab[i,60]==\"R\"):\n",
    "            nR+=1\n",
    "        else:\n",
    "            nM+=1\n",
    "    print(\"R \", label, \": \", 100*nR/nb)\n",
    "    print(\"M \",label, \": \", 100*nM/nb)\n",
    "repartition(data,\"total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa47ab9-200f-4405-a870-b07e5cc2bfaa",
   "metadata": {},
   "source": [
    "The goal is to split in 50% training and testing in order that the training and the testing dataset have almost the same label distribution. We try different random_state parameter for the built-in function train_test_split until getting something reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eebe075",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set = train_test_split(data, test_size=0.5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc6d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "R  total :  46.63461538461539\n",
      "M  total :  53.36538461538461\n",
      "104\n",
      "R  train :  48.07692307692308\n",
      "M  train :  51.92307692307692\n",
      "104\n",
      "R  test :  45.19230769230769\n",
      "M  test :  54.80769230769231\n"
     ]
    }
   ],
   "source": [
    "repartition(data,\"total\")\n",
    "repartition(train_set,\"train\")\n",
    "repartition(test_set,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96958e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X_train = train_set[:,0:60].astype(float)\n",
    "Y_train = train_set[:,60]\n",
    "X_test = test_set[:,0:60].astype(float)\n",
    "Y_test = test_set[:,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01417888-9592-4791-abea-1e259f5161ca",
   "metadata": {},
   "source": [
    "# Encode the output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d618617-14ed-4230-8680-ab8c870e91ea",
   "metadata": {},
   "source": [
    "In the original database the output are labeled by letter \"R\" or \"M\". Here, we assign number 0 or 1 to each label(one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69a06da",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "encoded_Y_test = encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07710ca1-0ed8-48d5-a780-601223d13ab1",
   "metadata": {},
   "source": [
    "# Normalization of the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9479b-c881-4d8d-aab5-5ea40d3b48f1",
   "metadata": {},
   "source": [
    "We do a standard normalization (mean 0 and standard deviation 1) in order to have the same scale for the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5adb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70115367",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42685edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = transformer.transform(X_train)\n",
    "X_test_prepared = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f28f4-7cf5-45ca-987d-cac9f71045ce",
   "metadata": {},
   "source": [
    "# Record the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09bf2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd6ce1-db08-493d-813f-f732cb0f07cb",
   "metadata": {},
   "source": [
    "We record the preprocessing data in csv files that we will use in the C/C++ code to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7fcd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('sonar_inputs_train.csv', X_train_prepared, delimiter=\",\")\n",
    "np.savetxt('sonar_outputs_train.csv', encoded_Y_train, delimiter=\",\")\n",
    "np.savetxt('sonar_inputs_test.csv', X_test_prepared, delimiter=\",\")\n",
    "np.savetxt('sonar_outputs_test.csv', encoded_Y_test, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
